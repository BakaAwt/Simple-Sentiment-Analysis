{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = [\"\", \"\"]\n",
    "ID = [2100000001, 2100000001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Finance Project: _Financial Statement Sentiment Analysis_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{DDL: Dec 18th, 2021}}$ \n",
    "\n",
    "$\\color{red}{\\text{Please noted, you are not allow to use packages that are from outside of this course}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dr. Pengfei Zhao**\n",
    "\n",
    "Finance Mathematics Program, \n",
    "\n",
    "BNU-HKBU United International College"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why sentiment analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Understanding Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentiment analysis, also known as opinion mining, refers to the use of natural language processing, text analysis and computational linguistics to identify and extract subjective information in source materials. (Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 How to do Sentiment Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A simple solution is, every word is given a score based on its extent of `positiveness`, `negativeness` or `neutral`. The Sentiment Analysis is done by calculating the algorithmic score of each word, and returning with the combined score for the given set of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 How Can The Sentiment Analysis API Be Applied In Financial Sector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The most common use of The Sentiment Analysis in financial sector will be the analysis of financial news, in particular to predicting the behaviour and possible trend of stock markets.\n",
    "\n",
    "* Traditional Technical Analysis of the Financial Market with the use of tools the like of Stockastics and Bollinger bands aside, sentiment analytics has been receiving a lot of attention as it allows the integration of both Fundamental Analysis (FA) and Technical Analysis (TA).\n",
    "\n",
    "* In real life, Financial Market Analysts make predictions on the stock market based on opinions and happenings in the news. Similarly, Sentiment Analysis technique is making it possible for computers to do the same job now. Further more, with advance computational linguistic and machine learning techniques, the task of opinion mining proves to be more efficient than human analysts, having the capability to scan through huge chunk of text across various news channels within seconds.\n",
    "\n",
    "* A simple example of the real application of Sentiment Analysis for the financial sector can be explained by the task of assigning positive, negative or neutral sentiment values to the words. For instance, words such as `good`, `benefit`, `positive`, `increase` and `growth` are all tagged with positive scores while words such as `decrease`, `risk`, `fall`, `bankruptcy`, and `loss` are tagged with negative scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 The Trend Of Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentiment Analysis has been heavily used by businesses for social media opinion mining, especially in the service industry, where customers feedback are critical. In recent years, it has been gaining popularity in the finance sector, where it has been used to analyze tweets of influential financial analysts and decision makers. It seems like there are so much potential to be unlocked for the usage of Sentiment Analysis. It is curious to what will be the next breakthrough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What you need to do in this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 What is already given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `train.txt`: contains 3877 rows with 3 columns \"index\", \"sentiment\", \"text\", where \"text\" denotes the financial news sentence, \"sentiment\" denotes the human annotated sentiment result (3 categories \"positive\", \"negative\", \"neutral\"), and \"index\" denotes the ID of the news sentence.\n",
    "* `test_x.txt`: contains 970 rows with 2 columns \"index\" and \"text\" whose explanation is the same as \"train.txt\". \n",
    "* `senti_dict.csv`: The sentiment word dictionary, where the value of each word indicates how positive of a word is. Negative score means the word tends to be negative. Note that this word sentiment dictionary is **not** guaranteed to be thorough and complete.\n",
    "* `fyi` folder: resources you may be interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 What you need to submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to submit a `zipped` package containing following files:\n",
    "\n",
    "* `test_y.txt`. You need to put your prediction results in a file named as \"test_y.txt\". The file contains 970 rows with 2 columns, in the form of `index,label`. \"index\" denotes the ID of corresponding sentence in \"text_x.txt\", and \"label\" denotes the sentiment you predict with respect to that sentence, which should be \"positive\", \"negative\", or  \"neutral\". \n",
    "\n",
    "* `.ipynb file`. You need to implement your solution in this jupyter notebook file, and add sufficient introduction to your thoughts and program (e.g. use highlight, bulletin, etc, just like the lecture slides), using the `markdown` language. \n",
    "\n",
    "    **Important:** your .ipynb file should be able to output (write) the \"test_y.txt\" to hard disk. If there is only the prediction result (test_y.txt) and your .ipynb file does not include the code which can output the prediction result, you will get **zero** marks. I will go into the .ipynb file and **run each cell of your program**. So, make sure your .ipynb is well organized so that I can easily find the part which can output your prediction result.\n",
    "\n",
    "* `sentiment_words_dict.txt (optional)`. If you use your own sentiment dictionary in the solution, you need to submit the dictionary used in your project as well.\n",
    "\n",
    "* In all, you need to submit all the materials so that I can successfully run your code and obtain the prediction result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 How to grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Project score will be based on:\n",
    "\n",
    "(1) The accuracy of your prediction result (test_y.txt). Accuracy is calculated based on how many labels you correctly predicted.\n",
    "\n",
    "(2) Your code and explanation written in the ipynb file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can use the sentiment in train.txt to validate your prediction strategy.\n",
    "* You can use the word sentiment score in ```senti_dict.csv``` to calculate the overall sentiment score of a sentence.\n",
    "* There has many sentiment words dictionary available online besides the provided 'senti_dict.csv', you can download the dictionary and use it in your projects.\n",
    "* You can use ```mark down``` to better edit your .ipynb file, e.g. add highlights, bold/italic font, images, tables, etc. You need to first set the cell as *Markdown* mode, instead of the *Code* mode. Markdown tutorial see [here](https://www.markdownguide.org/basic-syntax/) and [here](https://www.markdownguide.org/cheat-sheet/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 For Your Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentiment analysis technique have been widely applied to finance sector. Even though in this project you may only use the provided sentiment dictionary to judge the sentiment score of an article, in real world Artificial Intelligence (AI) and machine learning technique are largely used (e.g. to \"learn\" the sentiment score of each word). You can read more [here](https://emerj.com/ai-sector-overviews/ai-sentiment-analysis-finance-current-applications-possibilities/). \n",
    "* In 2011, a paper \"Twitter mood predicts the stock market\" (in ./fyi/ folder) draws great attention. People realize that the public sentiment may even influence the trend of stock price. Altough the effectiveness of applying sentiment analysis to stock price prediction task in this paper is doubted by other researchers later, sentiment analysis gradually becomes a widely accepted factor to facilitate analyse business. For example, below figure is a snapshot of \"富途证券\", and \"舆情指数\" becomes a standard component facilitating investors to analyse stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String Index             |  String Methods\n",
    ":-------------------------:|:-------------------------:\n",
    " <img src=\"/fyi/sentiment_explanation.jpeg\" width = \"380\" height = \"450\" alt=\"图片名称\" align=center />  |   <img src=\"/fyi/sentiment_example.jpeg\" width = \"380\" height = \"450\" alt=\"图片名称\" align=center />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Exploration\n",
    "\n",
    "As a beginner of python, I should hands on the concepts of NLP first.\n",
    "\n",
    "> Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. (Wikipedia)\n",
    "\n",
    "## Resolve of the Group Project\n",
    "\n",
    "### What we should do\n",
    "\n",
    "**Python for Finance Project:** *_Financial Statement Sentiment Analysis_*\n",
    "\n",
    "Literally, this project is closely related to financial mathematics, with the purpose of linking public opinion with financial trends.\n",
    "\n",
    "> Sentiment analysis, also known as opinion mining, refers to the use of natural language processing, text analysis and computational linguistics to identify and extract subjective information in source materials. (Wikipedia)\n",
    "\n",
    "The original document also mentioned:\n",
    "\n",
    "> A simple solution is, every word is given a score based on its extent of `positiveness`, `negativeness` or `neutral`. The Sentiment Analysis is done by calculating the algorithmic score of each word, and returning with the combined score for the given set of text.\n",
    "\n",
    "For each word, what we need is that we should calculate the individual word's point and return the point of the entire sentence.\n",
    "\n",
    "### What have been already given\n",
    "\n",
    "The difficult of this project is:\n",
    "\n",
    "**Please noted, you are not allow to use packages that are from outside of this course**\n",
    "\n",
    "This turned out to be the biggest obstacle for me to complete this project.\n",
    "\n",
    "So, I will start directly:\n",
    "\n",
    "> **3. What you need to do in this project**\n",
    ">\n",
    "> **3.1 What is already given**\n",
    ">\n",
    "> `train.txt`: contains 3877 rows with 3 columns \"index\", \"sentiment\", \"text\", where \"text\" denotes the financial news sentence, \"sentiment\" denotes the human annotated sentiment result (3 categories \"positive\", \"negative\", \"neutral\"), and \"index\" denotes the ID of the news sentence.\n",
    ">\n",
    "> `test_x.txt`: contains 970 rows with 2 columns \"index\" and \"text\" whose explanation is the same as \"train.txt\". \n",
    ">\n",
    "> `senti_dict.csv`: The sentiment word dictionary, where the value of each word indicates how positive of a word is. Negative score means the word tends to be negative. Note that this word sentiment dictionary is **not** guaranteed to be thorough and complete.\n",
    ">\n",
    "> `fyi` folder: resources you may be interested in.\n",
    "\n",
    "### What we need to submit\n",
    "\n",
    "> **3.2 What you need to submit**\n",
    ">\n",
    "> You need to submit a `zipped` package containing following files:\n",
    ">\n",
    "> `test_y.txt`. You need to put your prediction results in a file named as \"test_y.txt\". The file contains 970 rows with 2 columns, in the form of `index,label`. \"index\" denotes the ID of corresponding sentence in \"text_x.txt\", and \"label\" denotes the sentiment you predict with respect to that sentence, which should be \"positive\", \"negative\", or  \"neutral\". \n",
    ">\n",
    "> `.ipynb file`. You need to implement your solution in this jupyter notebook file, and add sufficient introduction to your thoughts and program (e.g. use highlight, bulletin, etc, just like the lecture slides), using the `markdown` language. \n",
    ">\n",
    "> **Important:** your .ipynb file should be able to output (write) the \"test_y.txt\" to hard disk. If there is only the prediction result (test_y.txt) and your .ipynb file does not include the code which can output the prediction result, you will get **zero** marks. I will go into the .ipynb file and **run each cell of your program**. So, make sure your .ipynb is well organized so that I can easily find the part which can output your prediction result.\n",
    ">\n",
    "> `sentiment_words_dict.txt (optional)`. If you use your own sentiment dictionary in the solution, you need to submit the dictionary used in your project as well.\n",
    ">\n",
    "> In all, you need to submit all the materials so that I can successfully run your code and obtain the prediction result.\n",
    "\n",
    "## Get Started with the Project\n",
    "\n",
    "### CSV Format Document Processing\n",
    "\n",
    "In the process of processing the raw materials, I found that the contents of `train.txt` and `test_x.txt` roughly conform to the format of the csv document, so they are processed together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "# Define global variables\n",
    "senti_dict = {}\n",
    "idf_dict = {}\n",
    "test_x = []\n",
    "test_y = []\n",
    "train = []\n",
    "custom_dict = {}\n",
    "merged_dict = {}\n",
    "accuCount = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handleData:\n",
    "\n",
    "    def __init__(self, senti_dict_path, test_x_path, test_y_path, train_path=None, custom_dict_path=None):\n",
    "        # Handle data\n",
    "        if not senti_dict_path:\n",
    "            print('Please input senti_dict_path')\n",
    "            quit()\n",
    "        else:\n",
    "            self.handle_senti_dict(senti_dict_path)\n",
    "        if not test_x_path:\n",
    "            print('Please input test_x_path')\n",
    "            quit()\n",
    "        else:\n",
    "            self.handle_test_x(test_x_path)\n",
    "        if not test_y_path:\n",
    "            print('Please input test_y_path')\n",
    "            quit()\n",
    "        if train_path:\n",
    "            self.handle_train(train_path)\n",
    "        if custom_dict_path:\n",
    "            self.handle_custom_dict(custom_dict_path)\n",
    "            merged_dict.update(custom_dict)\n",
    "        merged_dict.update(senti_dict)\n",
    "\n",
    "    def handle_senti_dict(self, path):\n",
    "        global senti_dict\n",
    "        # Preprocessing senti_dict type of dictionary\n",
    "        with open(path) as path:\n",
    "            csv_reader = csv.reader(path)\n",
    "            for line in csv_reader:\n",
    "                if csv_reader.line_num == 1:\n",
    "                    continue\n",
    "                senti_dict[line[1]] = float(line[2])\n",
    "            print('senti_dict library has %s line(s).' %len(senti_dict))\n",
    "\n",
    "    def handle_test_x(self, path):\n",
    "        global test_x\n",
    "        # Processing test_x type of two-dimensional array\n",
    "        with open(path) as path:\n",
    "            csv_reader = csv.reader(path)\n",
    "            for line in csv_reader:\n",
    "                line[0] = int(line[0])\n",
    "                test_x.append(line)\n",
    "            # test_x = sorted(test_x)\n",
    "            print('test_x library has %s line(s).' %len(test_x))\n",
    "\n",
    "    def handle_train(self, path):\n",
    "        global train\n",
    "        # Processing train type of two-dimensional array\n",
    "        with open(path) as path:\n",
    "            csv_reader = csv.reader(path)\n",
    "            for line in csv_reader:\n",
    "                if csv_reader.line_num == 1:\n",
    "                    continue\n",
    "                line[0] = int(line[0])\n",
    "                train.append(line)\n",
    "            # train = sorted(train)\n",
    "            print('train library has %s line(s).' %len(train))\n",
    "\n",
    "    def handle_custom_dict(self, path):\n",
    "        global custom_dict\n",
    "        # Preprocessing custom_dict type of dictionary\n",
    "        with open(path) as path:\n",
    "            csv_reader = csv.reader(path)\n",
    "            for line in csv_reader:\n",
    "                if csv_reader.line_num == 1:\n",
    "                    continue\n",
    "                custom_dict[line[0]] = float(line[1])\n",
    "                idf_dict[line[0]] = float(line[2])\n",
    "            print('custom_dict library has %s line(s).' %len(custom_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToCSV(list, path):\n",
    "    with open(path, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(list)\n",
    "        print('Results saved in %s' %path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()\n",
    "\n",
    "When it needs to be processed formally, just call it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('Python for Finance Project: Financial Statement Sentiment Analysis')\n",
    "    handleData('./senti_dict.csv', './test_x.txt', './test_y.txt', './train.txt', './sentiment_words_dict.txt')\n",
    "    if train != []:\n",
    "        listToCSV(sentimentAnalysis(train, 2), './test_train.txt')\n",
    "    else:\n",
    "        listToCSV(sentimentAnalysis(test_x, 1), './test_y.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among them, `'./train.txt'` and `'./sentiment_words_dict.txt'` are two optional parameters.\n",
    "\n",
    "### sentimentAnalysis() Part\n",
    "\n",
    "This part is the most troublesome place for me. Because this course has always emphasized the basics, there is no in-depth exploration of the algorithm part (only one kind of recursion is mentioned). So I could only cross the river by feeling the stones by myself, and I lost my mind.\n",
    "\n",
    "**And don't let the package be imported! **\n",
    "\n",
    "But the interesting point is that TA gave a thesaurus that seems to have nothing:\n",
    "\n",
    "| Words | Scores    |                        |\n",
    "| ----- | --------- | ---------------------- |\n",
    "| 0     | abil      | 0.00012416859533089645 |\n",
    "| 1     | actual    | 0.0006961488543271923  |\n",
    "| 2     | advertis  | -0.005592582215163179  |\n",
    "| 3     | agenc     | 0.0006353814403691496  |\n",
    "| 4     | aggreg    | -0.0010330308303088183 |\n",
    "| 5     | agreement | 7.96548813763754e-05   |\n",
    "| 6     | allow     | 0.002174006034169924   |\n",
    "| 7     | although  | -0.003593985395296731  |\n",
    "\n",
    "So, what do the numbers in the third column represent?\n",
    "\n",
    "~~(I still haven’t figured it out yet)~~\n",
    "\n",
    "But after comparison, it was found that these data came from here:\n",
    "\n",
    "https://github.com/nproellochs/SentimentDictionaries/blob/master/Dictionary8K.csv\n",
    "\n",
    "At the same time, the third column of the document given by the source is the Idf (inverse document frequency) data.\n",
    "\n",
    "| Words      | Scores                | Idf                |\n",
    "| ---------- | --------------------- | ------------------ |\n",
    "| abil       | 0.013451985735806887  | 2.440750228642685  |\n",
    "| abl        | -0.004787871091608642 | 1.9253479378492828 |\n",
    "| absolut    | 0.003360788277744489  | 2.728432301094466  |\n",
    "| academi    | 0.007129395655638781  | 2.9089206768067597 |\n",
    "| accent     | -0.003550084101686155 | 2.894374965804381  |\n",
    "| accept     | -0.010454735567790118 | 1.5262960445758316 |\n",
    "| accomplish | 0.004308459321682365  | 2.7162740966146566 |\n",
    "| act        | -0.022561708229224143 | 0.89426188633043   |\n",
    "| actor      | -0.011279482911515365 | 1.0184159310395977 |\n",
    "| actual     | -0.022918668083275685 | 1.5116972451546788 |\n",
    "\n",
    "This inspired me: Can we extract word frequencies to calculate the rarity of words in the text?\n",
    "\n",
    "> An easy way to think of is to find the word that appears most frequently. If a word is important, it should appear multiple times in this article. Therefore, we conduct \"term frequency\" (Term Frequency, abbreviated as TF) statistics.\n",
    ">\n",
    "> http://www.ruanyifeng.com/blog/2013/03/tf-idf.html\n",
    "\n",
    "At this time, there is an idea. We first extract the words of a given short sentence, and then count the total number of words in the sentence, the realization is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list\n",
    "def getWords(text):\n",
    "    # Use RegEx to extract the part that meets the specification\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # Lowercase all words and turn them into word list\n",
    "    words = text.lower().split()\n",
    "    # return words\n",
    "    return words\n",
    "\n",
    "# return an integer\n",
    "def countWords(text):\n",
    "    return len(getWords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, when performing word comparison, perform TF-IDF operation to get the word with the highest word frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of the word word in the sentence\n",
    "# Input word, sentence as string，idf as float\n",
    "def tf_idf(word, sentence, idf):\n",
    "    tf = getWords(sentence).count(word) / countWords(sentence)\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(data, num):\n",
    "    global accuCount\n",
    "    # -= Extract by line =-\n",
    "    # For test_x, line[0] is id，line[1] is sentence\n",
    "    # For train，line[0] is id，line[1] is given result, line[2] is sentence\n",
    "    # There are judgment statements for two data sources in main()\n",
    "    # index is the 0-based count of the sentence\n",
    "    for index, line in enumerate(data):\n",
    "        positiveCount = 0\n",
    "        negativeCount = 0\n",
    "        sum = 0\n",
    "        diff = 0\n",
    "        sentiPoint = 0.0\n",
    "        max_tf_idf = 0\n",
    "        max_word = ''\n",
    "        sentiType = 'neutral'\n",
    "        # -= Perform judgment in units of words =-\n",
    "        # Count the number of positive and negative words separately\n",
    "        # line[num] as string\n",
    "        for word in getWords(line[num]):\n",
    "            # find word in dictionary\n",
    "            # merged_dict[word] idf_dict[word]\n",
    "            if word in merged_dict:\n",
    "                tf_idf_val = tf_idf(word, line[num], idf_dict[word])\n",
    "                if tf_idf_val > max_tf_idf:\n",
    "                    max_tf_idf = tf_idf_val\n",
    "                    max_word = word\n",
    "        if max_word != '':\n",
    "            if merged_dict[max_word] > 0.01:\n",
    "                sentiType = 'positive'\n",
    "            elif merged_dict[max_word] < -0.01:\n",
    "                sentiType = 'negative'\n",
    "            else:\n",
    "                sentiType = 'neutral'\n",
    "        else:\n",
    "            sentiType = 'neutral'\n",
    "        test_y.append([line[0], sentiType])\n",
    "        if sentiType == line[1]:\n",
    "            accuCount += 1\n",
    "    # Calculate accuracy using train.txt \n",
    "    if num == 2:\n",
    "        print('Accuracy is %s.' %(accuCount / len(data)))\n",
    "    return test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can already get good things:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kirin@KirindeMacBook-Pro Senti % python3 main.py\n",
    "Python for Finance Project: Financial Statement Sentiment Analysis\n",
    "senti_dict library has 172 line(s).\n",
    "test_x library has 970 line(s).\n",
    "train library has 3876 line(s).\n",
    "custom_dict library has 683 line(s).\n",
    "Accuracy is 0.5092879256965944.\n",
    "Results saved in ./test_train.txt\n",
    "kirin@KirindeMacBook-Pro Senti % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run my program, please using python3 \"./main.py\" and check the \"./text_y.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
